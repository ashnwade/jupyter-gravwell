{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956b106-7232-4c7d-a562-b2f7bc71e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run gravwell-lib.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00671834-0623-46c0-9fc9-88a6ddc762f6",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook demonstrates how you can pull data from Gravwell queries into a Jupyter notebook.\n",
    "\n",
    "Note the `%run gravwell-lib.ipynb` cell at the top--that imports the necessary code from another notebook residing in the current directory. To use Gravwell in your own notebook, copy that `gravwell-lib.ipynb` into the directory where *your* notebook resides and insert the same code cell at the top.\n",
    "\n",
    "To pull data from Gravwell, we use the `query` function, which takes two arguments: the Gravwell query to run, and the duration over which to run. The duration is something like \"-24h\" or \"-5m\", to indicate \"the last 24 hours\" or \"the last 5 minutes\", respectively. You can also specify explicit start and end times, rather than a duration (demonstrated later in this notebook).\n",
    "\n",
    "The `query` function returns a `pandas.DataFrame` object suitable for plotting and other manipulations.\n",
    "\n",
    "### About the Demo Server\n",
    "\n",
    "The queries in this notebook are executed against **demo.gravwell.io** (provided you haven't modified the `GravwellToken` and `GravwellServer` variables in `gravwell-lib.ipynb`).\n",
    "\n",
    "This server has some basic data in the following tags:\n",
    "\n",
    "* `pinger`: collects the round-trip time to various hosts on the Internet\n",
    "* `stocks`: queries the Yahoo stocks API for stock market prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e46d139-91a8-430f-874b-c4ab0421f196",
   "metadata": {},
   "source": [
    "# Raw Entries\n",
    "To start with, we might pull back some raw entries from the `stocks` tag, filtering to only show 5 results for the AAPL ticker symbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8ab79-2ad3-4010-9649-18292f0de506",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = query(\"tag=stocks json Ticker==AAPL | limit 5\", \"-24h\")\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206cb607-4c39-428e-a6e6-e1c3cf15f972",
   "metadata": {},
   "source": [
    "Note how the DataFrame returned contains a Timestamp, Source, and Tag field in addition to the actual stocks data itself. If we want to see just the data fields, we can iterate over the results and print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2046871-4226-423e-b380-4f43975301f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in raw[\"Data\"]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed2c0a-b851-46b0-ab38-9b05ae925774",
   "metadata": {},
   "source": [
    "# Tables\n",
    "Because the `query` function returns a pandas.DataFrame object, it's already essentially a table and thus we don't really need to do much to display our results. Here is a basic table query run over the last hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c5a49-30d4-48e4-891d-d81b6089faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = query(\"tag=pinger ax | stats mean(ms) as ms stddev(ms) by host ip | table protocol host ip ms stddev\", \"-1h\")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba776b50-03a7-4892-b02d-b2c645558172",
   "metadata": {},
   "source": [
    "# Charts\n",
    "Now let's run a query using the chart renderer. Note that we call the same function as before: `query`. After running the query, if we just display the `chart` variable, we can see the data points rendered in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d3ad4-9243-4fae-90b5-221ab18654e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = query(\"tag=pinger ax | stats mean(ms) by host | chart mean by host\", \"-1h\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ad093-b6d5-4aaa-8e5b-20d22dd998ec",
   "metadata": {},
   "source": [
    "To make a chart, we'll use the matplotlib library (imported in `gravwell-lib.ipynb` as `plt`). Here, we indicate that the column named \"Timestamp\" is the index column, then iterate over all the others to generate plots for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3081278-e9c0-475b-8563-087d5cd8eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = query(\"tag=pinger ax | stats mean(ms) by host | chart mean by host\", \"-24h\")\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.ylabel(\"milliseconds\")\n",
    "for column_name in chart.set_index(\"Timestamp\"):\n",
    "    plt.plot(chart[\"Timestamp\"],chart[column_name],label=column_name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6155e5-4be6-4ffb-818f-a14fce8225f6",
   "metadata": {},
   "source": [
    "If we're not interested in timeseries data, it makes more sense to run our query using the table renderer, then chart the results. Thus we can take the average response times from our earlier query and format it as a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d888d-aa15-4373-800e-94df360e645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.set_index(\"host\").plot.bar(y=\"ms\", figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed80749-089a-43b2-bcca-58ba7231c2a1",
   "metadata": {},
   "source": [
    "Of course we can also do interesting things like plot error bars using the standard deviation column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2d76e-0470-4ff2-bfe8-6f251bd61b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.ylabel(\"milliseconds\")\n",
    "plt.errorbar(table[\"host\"],table[\"ms\"],fmt=\".\",yerr=table[\"stddev\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c6a2f-da0a-477f-91cc-f4874954e5b5",
   "metadata": {},
   "source": [
    "# Specifying Exact Timeframes\n",
    "Sometimes, \"run the query over the last N hours\" isn't good enough--you need to run the query over a particular time frame. Maybe you're building a notebook to investigate trends in the stock market between May 8 and May 14, 2022. In this case, you can specify the `start` and `end` parameters to the query function. These should be RFC3339 (ISO 8601) timestamp strings. You can generate those strings by hand, or you can use the datetime library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4720451-305d-4595-a5c4-02cc703be7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "now=datetime.datetime.now().astimezone().isoformat()\n",
    "now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddacf88b-fadd-4b67-9ba0-cd0b0bd85763",
   "metadata": {},
   "source": [
    "The `astimezone()` function with no arguments puts the timestamps into the local time zone. If we instead want UTC, we can specify a timezone as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5f1d92-de92-44c1-80f4-3a37f7db8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.datetime.fromisoformat('2022-05-08').astimezone(pytz.utc).isoformat()\n",
    "end=datetime.datetime.fromisoformat('2022-05-14').astimezone(pytz.utc).isoformat()\n",
    "start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9af5e9-20de-43e0-932f-4ba6735844b1",
   "metadata": {},
   "source": [
    "With `start` and `end` variables defined, we can pass them to a query and thus chart the number of `stocks` entries in those dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e42be0-69cb-454d-9541-a198ee4b0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = query(\"tag=stocks json Ticker==AAPL High | stats mean(High) by Ticker | chart mean by Ticker\", start=start, end=end)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.ylabel(\"Price\")\n",
    "plt.plot(x[\"Timestamp\"],x[\"AAPL\"],label=\"AAPL\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec229a0f-e61a-4c27-9ad0-5f1d95328380",
   "metadata": {},
   "source": [
    "If we find the \"jumps\" between trading days to be confusing, we can instead use a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd478c0-c298-4da4-8887-122834018a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.ylabel(\"Price\")\n",
    "plt.scatter(x[\"Timestamp\"],x[\"AAPL\"],label=\"AAPL\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f181c8-a046-4089-8540-8e316d56ea4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "John Floren"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "title": "Gravwell Report"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
